[ft_instance_hyperparameter]
data_type=fp16
enable_custom_all_reduce=0

tensor_para_size=1
pipeline_para_size=1

model_name=decoder
model_dir=/notebooks/models/m2m-ft/1/1-gpu/

[request]
beam_width=1 # beam width for beam search
top_k=1 ; k value for top k sampling
top_p=0.0 ; p value for top p sampling
temperature=1.0 ; Use for sampling
repetition_penalty=1.0 ; Use for sampling
presence_penalty=0.0  ; Only one of repetition_penalty and presence_penalty are allowed.
len_penalty=0.0
beam_search_diversity_rate=0.0
request_batch_size=1 # determine by the request
request_output_len=32 # determine by the request

[encoder]
model_name = m2m
num_heads = 16
d_kv = 64
d_model = 1024
d_ff = 8192
num_layers = 24
vocab_size = 128112
max_pos_seq_len = 1024
feed_forward_proj = relu
weight_data_type = fp16

[decoder]
num_heads = 16
d_kv = 64
d_model = 1024
d_ff = 8192
num_layers = 24
vocab_size = 128112
max_pos_seq_len = 1024
decoder_start_token_id = 2
eos_token_id = 2
weight_data_type = fp16
forced_bos_id = 128028
